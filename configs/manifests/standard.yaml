# nireon_v4\configs\manifests\standard.yaml
version: '1.0'
metadata:
  name: NireonV4 Standard Setup for Explorer Test
  description: Manifest to bootstrap core services and Explorer for testing Gateway magic.
  author: NIREON Team
  created_at: '2025-06-05T10:00:00Z'
  updated_at: '2025-06-07T12:00:00Z'

shared_services:
  llm_router_main:
    enabled: true
    preload: true
    class: infrastructure.llm.router:LLMRouter
    port_type: domain.ports.llm_port:LLMPort
    metadata_definition: infrastructure.llm.router:LLM_ROUTER_METADATA
    config:
      id: llm_router_main
      # CORRECTED: The default route is named 'default'.
      default: default 
      routes:
        # This defines the route named 'default' and maps it to the 'nano_default' model.
        default: nano_default 
        chat_fast: nano_default
        research: nano_default
        analysis: nano_default
        sentinel_axis_scorer: nano_default
      enable_circuit_breakers: true
      enable_health_checks: true
      enable_metrics: true
      health_check_interval: 300
      circuit_breaker_defaults:
        failure_threshold: 5
        recovery_timeout: 60
        success_threshold: 3
        timeout: 30
      models:
        nano_default:
          provider: openai
          model_name_for_api: gpt-4o-mini
          backend: infrastructure.llm.generic_http:GenericHttpLLM
          method: POST
          base_url: https://api.openai.com/v1
          endpoint: /chat/completions
          auth_style: bearer
          auth_token_env: OPENAI_API_KEY
          timeout: 60
          payload_template: |
            {
              "model": "{{ model_name_for_api }}",
              "messages": [
                {"role": "system", "content": "{{ system_prompt }}"},
                {"role": "user",   "content": "{{ prompt }}"}
              ],
              "temperature": {{ temperature }},
              "top_p": {{ top_p }},
              "max_tokens": {{ max_tokens }}
            }
          response_text_path: $.choices[0].message.content
        mock_testing_model:
          provider: mock
          backend: infrastructure.llm.mock_llm:MockLLM
          timeout: 5
        openai_gpt4_specific:
          provider: openai
          backend: infrastructure.llm.generic_http:GenericHttpLLM
          method: POST
          base_url: https://api.openai.com/v1
          endpoint: /chat/completions
          auth_style: bearer
          auth_token_env: OPENAI_API_KEY
          timeout: 120
          model_name_for_api: gpt-4o-mini
          payload_template: |
            {
              "model": "{{ model_name_for_api }}",
              "messages": [
                {"role": "system", "content": "{{ system_prompt }}"},
                {"role": "user",   "content": "{{ prompt }}"}
              ],
              "temperature": {{ temperature }},
              "top_p": {{ top_p }},
              "max_tokens": {{ max_tokens }}
            }
          response_text_path: $.choices[0].message.content

  EmbeddingPort:
    enabled: true
    preload: true
    class: infrastructure.embeddings.sentence_transformer_adapter:SentenceTransformerAdapter
    port_type: domain.ports.embedding_port:EmbeddingPort
    config:
      model_name: all-MiniLM-L6-v2
      dimensions: 384
      cache_size: 1000

  vector_memory_inmemory:
    enabled: true
    preload: true
    class: infrastructure.vector_memory.inmemory_store:InMemoryVectorStore
    port_type: domain.ports.vector_memory_port:VectorMemoryPort
    metadata_definition: infrastructure.vector_memory.inmemory_store:INMEMORY_VECTOR_STORE_METADATA
    config:
      dimensions: 384
      similarity_metric: cosine
      capacity: 100000

  embedding_service_main:
    enabled: true
    preload: true
    class: application.services.embedding_service:EmbeddingService
    metadata_definition: application.services.embedding_service:EMBEDDING_SERVICE_METADATA
    config:
      provider: sentence_transformers
      embedding_port_id: EmbeddingPort
      vector_memory_ref: vector_memory_inmemory # Use the new in-memory store
      novelty_threshold: 0.75
      cache_size: 1000

  EventBusPort:
    enabled: true
    preload: true
    class: infrastructure.event_bus.memory_event_bus:MemoryEventBus

  IdeaRepositoryPort:
    enabled: true
    preload: true
    class: infrastructure.persistence.idea_repository:IdeaRepository
    port_type: domain.ports.idea_repository_port:IdeaRepositoryPort
    config:
      provider: sqlite
      db_path: runtime/nireon_ideas.db
      enable_wal_mode: true
      timeout: 30.0

  IdeaService:
    enabled: true
    preload: true
    class: application.services.idea_service:IdeaService
    metadata_definition: application.services.idea_service:IDEA_SERVICE_METADATA
    config:
      repository_port_id: IdeaRepositoryPort    # ← injects the repo
      event_bus_port_id: EventBusPort           # ← optional but useful

  parameter_service_global:
    enabled: true
    preload: true
    class: infrastructure.llm.parameter_service:ParameterService
    metadata_definition: infrastructure.llm.parameter_service:PARAMETER_SERVICE_METADATA
    config:
      storage_backend: memory

  frame_factory_service:
    enabled: true
    preload: true
    class: application.services.frame_factory_service:FrameFactoryService
    port_type: application.services.frame_factory_service:FrameFactoryService
    metadata_definition: application.services.frame_factory_service:FRAME_FACTORY_SERVICE_METADATA
    config:
      default_frame_type: epistemic
      log_frame_operations: true

  budget_manager_inmemory:
    enabled: true
    preload: true
    class: application.services.budget_manager:InMemoryBudgetManager
    port_type: domain.ports.budget_manager_port:BudgetManagerPort
    metadata_definition: application.services.budget_manager:BUDGET_MANAGER_METADATA
    config:
      initial_budgets:
        llm_calls: 10.0
        event_publishes: 100.0
        embedding_calls: 50.0

  mechanism_gateway:
    enabled: true
    preload: false
    class: infrastructure.gateway.mechanism_gateway:MechanismGateway
    metadata_definition: infrastructure.gateway.mechanism_gateway_metadata:MECHANISM_GATEWAY_METADATA
    config_override:
      id: mechanism_gateway

composites: {}

mechanisms:
  explorer_instance_01:
    enabled: true
    class: components.mechanisms.explorer.service:ExplorerMechanism
    metadata_definition: components.mechanisms.explorer.service:EXPLORER_METADATA
    metadata_override:
      epistemic_tags: ['generator', 'mutator', 'innovator']
    config: configs/default/mechanisms/{id}.yaml
    config_override:
      application_rate: 0.8
      max_depth: 10
      exploration_strategy: depth_first

  sentinel_instance_01:
    enabled: true
    class: components.mechanisms.sentinel.service:SentinelMechanism
    metadata_definition: components.mechanisms.sentinel.metadata.SENTINEL_METADATA
    metadata_override:
      epistemic_tags: ['evaluator', 'quality_control', 'gatekeeper']
    config: configs/default/mechanisms/{id}.yaml
    config_override:
      trust_threshold: 3.5

  catalyst_instance_01:
    enabled: true
    class: components.mechanisms.catalyst.service:CatalystMechanism
    metadata_definition: components.mechanisms.catalyst.metadata:CATALYST_METADATA
    metadata_override:
      epistemic_tags: ['synthesizer', 'cross_pollinator']
    config: configs/default/mechanisms/{id}.yaml
    config_override:
      application_rate: 0.5
      blend_high: 0.4
      anti_constraints_enabled: true
      duplication_check_enabled: true

observers: {}
managers: {}

orchestration_commands:
  system_orchestrator:
    enabled: true
    metadata_definition: bootstrap.bootstrap_helper.metadata:create_orchestration_command_metadata
    metadata_override:
      id: system_orchestrator
      name: System Test Orchestrator
      description: A virtual component representing the test runner or external caller.
      produces:
        - SEED_SIGNAL
        - EXPLORATION_REQUEST
        - CATALYSIS_REQUEST
        - COGNITIVE_EVENT_PUBLISH
        - COGNITIVE_EVENT_LLM_ASK
        - FRAME_CREATION_REQUEST
        - FRAME_UPDATE_REQUEST
        - NOVELTY_CHECK      
        - EMBEDDING_REQUEST 

environment_overrides:
  development:
    shared_services: {}
  testing:
    shared_services: {}
  production:
    shared_services: {}